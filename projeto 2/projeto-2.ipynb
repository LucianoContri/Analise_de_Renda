{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previsão de renda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 elementos importantes\n",
    "- Esse notebook\n",
    "- Streamlit com as análises\n",
    "- Seu Github com o projeto\n",
    "- Vídeo no readme do github mostrando o streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 1 CRISP - DM: Entendimento do negócio\n",
    "\n",
    "Esse projeto tem como objetivo prever a renda de um cliente baseado em suas características pessoais. A renda é uma variável importante para diversas aplicações, como concessão de crédito, análise de risco, entre outras. A previsão de renda pode ser utilizada para segmentar clientes, personalizar ofertas e otimizar a experiência do cliente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 2 Crisp-DM: Entendimento dos dados\n",
    "\n",
    "Nesta etapa, vamos entender os dados que temos disponíveis para a previsão de renda. Vamos analisar as variáveis disponíveis, o tipo de dado de cada variável, a distribuição dos dados e a relação entre as variáveis.\n",
    "\n",
    "\n",
    "### Dicionário de dados\n",
    "\n",
    "\n",
    "\n",
    "| Variável                |                                         Descrição                                         |       Tipo |\n",
    "| ----------------------- |:-----------------------------------------------------------------------------------------:|-----------:|\n",
    "| data_ref                |               Data de referência para os dados coletados (formato YYYYMM).\t               |   int64    |\n",
    "| id_cliente              |                             Identificador único do cliente.\t                              |  object    |\n",
    "| sexo                    |                   Sexo do cliente (0 para feminino, 1 para masculino).\t                   |   int64    |\n",
    "| posse_de_veiculo        |                   Indica se o cliente possui um veículo (sim/não).\t                       |  object    |\n",
    "| posse_de_imovel         |          Indica se o cliente possui um imóvel (True para sim, False para não).\t           |    bool    |\n",
    "| qtd_filhos              |                        Quantidade de filhos que o cliente possui.                         |    bool    |\n",
    "| tipo_renda              |           Tipo de renda do cliente (por exemplo, assalariado, autônomo, etc.).\t           |   int64    |\n",
    "| educacao                | Nível de educação do cliente (por exemplo, ensino médio, graduação, pós-graduação, etc.). |  object    |\n",
    "| estado_civil            |        Estado civil do cliente (por exemplo, solteiro, casado, divorciado, etc.).\t        |  object    |\n",
    "| tipo_residencia         |        Tipo de residência do cliente (por exemplo, casa própria, alugado, etc.).\t         |  object    |\n",
    "| idade                   |                                    Idade do cliente.\t                                     |  object    |\n",
    "| tempo_emprego           |                        Tempo de emprego atual do cliente em anos.\t                        |   int64    |\n",
    "| qt_pessoas_residencia   |               Quantidade de pessoas que residem na mesma casa do cliente.\t                | float64    |\n",
    "| renda                   |                                 Renda mensal do cliente.\t                                 | float64    |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregando os pacotes\n",
    "É considerado uma boa prática carregar os pacotes que serão utilizados como a primeira coisa do programa."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T19:06:42.985063Z",
     "start_time": "2024-05-28T19:06:42.981758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from ydata_profiling.controller.pandas_decorator import profile_report\n",
    "\n"
   ],
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregando os dados\n",
    "O comando pd.read_csv é um comando da biblioteca pandas (pd.) e carrega os dados do arquivo csv indicado para um objeto *dataframe* do pandas."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T19:06:43.587930Z",
     "start_time": "2024-05-28T19:06:43.560626Z"
    }
   },
   "source": [
    "renda = pd.read_csv('./input/previsao_de_renda.csv')"
   ],
   "execution_count": 51,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T19:06:43.598495Z",
     "start_time": "2024-05-28T19:06:43.588933Z"
    }
   },
   "source": [
    "renda.head(1)"
   ],
   "execution_count": 52,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entendimento dos dados - Univariada\n",
    "Nesta etapa tipicamente avaliamos a distribuição de todas as variáveis. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-05-28T19:06:50.004408Z",
     "start_time": "2024-05-28T19:06:43.643045Z"
    }
   },
   "source": [
    "prof = profile_report(renda, explorative=True, minimal=True)\n",
    "prof\n"
   ],
   "execution_count": 53,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T19:06:50.020483Z",
     "start_time": "2024-05-28T19:06:50.006414Z"
    }
   },
   "source": [
    "prof.to_file('./output/renda_analisys.html')"
   ],
   "execution_count": 54,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "renda.dtypes",
   "execution_count": 55,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Relatório do profiler, tivemos os seguintes alertas:\n",
    "\n",
    "1. **tempo_emprego** has 2573 (17.2%) missing values\n",
    "    - Precisa ser tratado!\n",
    "2. **Unnamed: 0** has unique values\n",
    "    - Provavelmente é um índice.\n",
    "3. **qtd_filhos** has 10376 (69.2%) zeros\n",
    "    - É um valor esperado, a taxa de natalidade vem caindo.\n",
    "4. A **Distribuição** das variaveis numéricas parecem respeitar a distribuição normal.\n",
    "5. **dados_ref** é uma data, mas está como object.\n",
    "6. **sexo, tipo_renda, educacao, estado_civil e tipo_residencia** são categóricas. Criar dummies.\n",
    "7. **educacao** é uma variável ordinal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entendimento dos dados - Bivariadas\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploração Visual das Relações:\n",
    "\n",
    "    1. Gráficos de Dispersão: Para duas variáveis numéricas.\n",
    "    2. Gráficos de Barras: Para uma variável categórica e uma numérica (ex.: média da variável numérica para cada categoria).\n",
    "    3. Heatmaps de Correlação: Para visualizar a matriz de correlação entre variáveis numéricas.\n",
    "    4. Cálculo de Correlações:\n",
    "\n",
    "Coeficiente de Correlação de Pearson: Para medir a força e a direção da relação linear entre duas variáveis numéricas.\n",
    "Correlação de Spearman: Para variáveis numéricas que não seguem uma distribuição normal.\n",
    "Cálculo de Associação: Para variáveis categóricas (ex.: teste qui-quadrado).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T19:06:53.728488Z",
     "start_time": "2024-05-28T19:06:50.027593Z"
    }
   },
   "source": [
    "%matplotlib inline\n",
    "# Gráficos de Dispersão das variáveis numéricas [renda, idade, tempo_emprego, qt_pessoas_residencia]\n",
    "sns.pairplot(renda[['renda', 'idade', 'tempo_emprego', 'qt_pessoas_residencia']], corner=True)\n",
    "plt.savefig('./output/pairplot.png')\n",
    "plt.show()"
   ],
   "execution_count": 56,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T19:06:56.181055Z",
     "start_time": "2024-05-28T19:06:53.729494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Gráficos de Barras das variáveis categóricas em relação a renda\n",
    "# plotando as 6 figuras juntas\n",
    "fig, axs = plt.subplots(2, 4, figsize=(20, 10))\n",
    "# Ordenar por renda média\n",
    "sexo_order = renda.groupby('sexo')['renda'].mean().sort_values().index\n",
    "posse_de_veiculo_order = renda.groupby('posse_de_veiculo')['renda'].mean().sort_values().index\n",
    "posse_de_imovel_order = renda.groupby('posse_de_imovel')['renda'].mean().sort_values().index\n",
    "educacao_order = renda.groupby('educacao')['renda'].mean().sort_values().index\n",
    "estado_civil_order = renda.groupby('estado_civil')['renda'].mean().sort_values().index\n",
    "tipo_residencia_order = renda.groupby('tipo_residencia')['renda'].mean().sort_values().index\n",
    "tipo_renda_order = renda.groupby('tipo_renda')['renda'].mean().sort_values().index\n",
    "\n",
    "# Criar os barplots ordenados\n",
    "sns.barplot(x='sexo', y='renda', data=renda, order=sexo_order, ax=axs[0, 0])\n",
    "sns.barplot(x='posse_de_veiculo', y='renda', data=renda, order=posse_de_veiculo_order, ax=axs[0, 1])\n",
    "sns.barplot(x='posse_de_imovel', y='renda', data=renda, order=posse_de_imovel_order, ax=axs[0, 2])\n",
    "sns.barplot(x='tipo_renda', y='renda', data=renda, order=tipo_renda_order, ax=axs[0, 3])\n",
    "sns.barplot(x='educacao', y='renda', data=renda, order=educacao_order, ax=axs[1, 0])\n",
    "sns.barplot(x='estado_civil', y='renda', data=renda, order=estado_civil_order, ax=axs[1, 1])\n",
    "sns.barplot(x='tipo_residencia', y='renda', data=renda, order=tipo_residencia_order, ax=axs[1, 2])\n",
    "\n",
    "\n",
    "# Remover o gráfico extra vazio\n",
    "fig.delaxes(axs[1, 3])\n",
    "\n",
    "# Rotacionar os rótulos do eixo x para todos os gráficos\n",
    "for ax in axs.flat:\n",
    "    if ax:\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./output/barplots.png')\n",
    "plt.show()"
   ],
   "execution_count": 57,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T19:06:56.189649Z",
     "start_time": "2024-05-28T19:06:56.181055Z"
    }
   },
   "cell_type": "code",
   "source": "renda.isna().sum().sort_values(ascending=False) # Verificar valores faltantes.",
   "execution_count": 58,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T19:06:56.203299Z",
     "start_time": "2024-05-28T19:06:56.190652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "renda = (renda.drop(columns=['Unnamed: 0', 'data_ref', 'id_cliente'])\n",
    "              .dropna()) # Remover linhas com valores faltantes, pois são poucas.\n",
    "renda.isna().sum().sort_values(ascending=False) # Verificar se ainda existem valores faltantes."
   ],
   "execution_count": 59,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T00:50:35.543187Z",
     "start_time": "2024-05-29T00:50:34.637710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Selecionar apenas colunas numéricas\n",
    "numeric_columns = renda.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Heatmap de correlação de Pearson\n",
    "# Heatmap de correlação de Spearman\n",
    "plt.figure(figsize=(15, 12))  # Increase the size of the plot\n",
    "spearman_corr = renda[numeric_columns].corr(method='pearson')\n",
    "sns.heatmap(spearman_corr,annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "\n",
    "\n",
    "plt.title('Heatmap de Correlação de Pearson')\n",
    "plt.savefig('./output/heatmap_pearson.png')  \n",
    "plt.show()\n",
    "\n",
    "# Heatmap de correlação de Spearman\n",
    "plt.figure(figsize=(15, 12))  # Increase the size of the plot\n",
    "spearman_corr = renda[numeric_columns].corr(method='spearman')\n",
    "sns.heatmap(spearman_corr,annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "\n",
    "plt.title('Heatmap de Correlação de Spearman')\n",
    "plt.savefig('./output/heatmap_spearman.png') \n",
    "plt.show()"
   ],
   "execution_count": 85,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    ")1. dispersão: não parece haver uma relação linear forte entre as variáveis numéricas e a renda.\n",
    "2. barras: existe uma diferença na renda média entre as categorias das variáveis categóricas menos para a variável **posse_de_imovel**.\n",
    "3. heatmaps: não parece haver uma correlação forte entre as variáveis numéricas e a renda. Mas a correlação de renda com tempo_emprego pode ser interessante.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Etapa 3 Crisp-DM: Preparação dos dados\n",
    "Nessa etapa realizamos tipicamente as seguintes operações com os dados:\n",
    "\n",
    " - **seleção**: Já temos os dados selecionados adequadamente?\n",
    " - **limpeza**: Precisaremos identificar e tratar dados faltantes\n",
    " - **construção**: construção de novas variáveis\n",
    " - **integração**: Temos apenas uma fonte de dados, não é necessário integração\n",
    " - **formatação**: Os dados já se encontram em formatos úteis?\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " - seleção: Já temos os dados selecionados adequadamente?\n",
    "    - **Não**. Precisamos remover a coluna **Unnamed: 0**.\n",
    " - limpeza: Precisaremos tratar dados faltantes em **tempo_emprego**. \n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Construção de novas variáveis não é necessária.\n",
    "- integração: Temos apenas uma fonte de dados, não é necessário integração.\n",
    "- formatação: criaremos dummies para as variáveis categóricas."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T19:06:57.166892Z",
     "start_time": "2024-05-28T19:06:57.075427Z"
    }
   },
   "source": [
    "# Criar dummies para as variáveis categóricas\n",
    "renda = pd.get_dummies(renda, columns=['sexo', 'tipo_renda', 'educacao', 'estado_civil', 'tipo_residencia'], drop_first=True)\n",
    "\n",
    "# Converter colunas uint8 para bool\n",
    "for col in renda.select_dtypes(['uint8']).columns:\n",
    "    renda[col] = renda[col].astype(bool)\n",
    "\n",
    "# salvar o arquivo\n",
    "renda.to_csv('./output/renda_preparada.csv', index=False)\n",
    "renda.dtypes\n"
   ],
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 4 Crisp-DM: Modelagem\n",
    "Nessa etapa que realizaremos a construção do modelo. Os passos típicos são:\n",
    "- Selecionar a técnica de modelagem\n",
    "- Desenho do teste\n",
    "- Avaliação do modelo\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Como em tarefas passadas já realizei regressão e árvore nesse dataset quero tentar algo novo,\n",
    "utilizarei o TPOT para encontrar o melhor modelo para prever a renda. O tpot usa o sklearn com scripts prontos para testar vários modelos para tentar encontrar o melhor."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T19:06:57.182824Z",
     "start_time": "2024-05-28T19:06:57.167895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Supondo que 'renda' seja a variável alvo e as demais sejam features\n",
    "X = renda.drop('renda', axis=1)\n",
    "y = renda['renda']\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalar os dados\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rodando o modelo\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T19:06:57.187875Z",
     "start_time": "2024-05-28T19:06:57.183827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from timeit import default_timer as timer\n",
    "# Teste de Resíduos\n",
    "from scipy.stats import shapiro, levene\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Criar um DataFrame para salvar os resultados\n",
    "results_df = pd.DataFrame(columns=['model', 'execution_time', 'r2', 'shapiro', 'levene', 'het_breuschpagan'])"
   ],
   "execution_count": 63,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### TPOT"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T19:09:15.252850Z",
     "start_time": "2024-05-28T19:06:57.188876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "from tpot import TPOTRegressor, TPOTClassifier\n",
    "\n",
    "\n",
    "# Inicializar o TPOTClassifier\n",
    "tpot = TPOTRegressor(generations=3, population_size=10, verbosity=2, random_state=42)\n",
    "\n",
    "# Treinar o TPOTClassifier\n",
    "start = timer()\n",
    "tpot.fit(X_train, y_train)\n",
    "end = timer()\n",
    "\n",
    "# gerar previsões para calcular o R2 Score e salvar com o tempo de execução\n",
    "y_pred = tpot.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "residuals = y_test - y_pred\n",
    "_, p_value_het, _, _ = het_breuschpagan(residuals, X_test)\n",
    "_, p_value_lev = levene(residuals, y_test)\n",
    "_, p_value_shap = shapiro(residuals)\n",
    "\n",
    "results_df.loc[len(results_df)] = ['TPOT', end - start, r2, p_value_shap, p_value_lev, p_value_het] \n",
    "\n",
    "# Exportar o pipeline otimizado\n",
    "tpot.export('./output/tpot_pipeline.py')"
   ],
   "execution_count": 64,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Vou tentar brevemente fazer uma regressão linear e uma árvore de decisão com busca de hiperparametros para comparar os resultados."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Regressão Linear"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T19:09:15.268921Z",
     "start_time": "2024-05-28T19:09:15.253851Z"
    }
   },
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Inicializar o modelo\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Treinar o modelo\n",
    "\n",
    "# usar timeit para medir o tempo de execução\n",
    "\n",
    "start = timer()\n",
    "lr.fit(X_train, y_train)\n",
    "end = timer()\n",
    "\n",
    "\n",
    "# R2 Score com sklearn\n",
    "y_pred = lr.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "residuals = y_test - y_pred\n",
    "_, p_value_het, _, _ = het_breuschpagan(residuals, X_test)\n",
    "_, p_value_lev = levene(residuals, y_test)\n",
    "_, p_value_shap = shapiro(residuals)\n",
    "\n",
    "# Salvar os resultados no DataFrame\n",
    "results_df.loc[len(results_df)] = ['Linear Regression', end - start, r2, p_value_shap, p_value_lev, p_value_het]\n",
    "\n",
    "joblib.dump(lr, './output/linear_regression_model.pkl')\n",
    "\n",
    "print(f'R2 Score: {r2:.2f}')"
   ],
   "execution_count": 65,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Árvore de Decisão"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T19:11:18.687933Z",
     "start_time": "2024-05-28T19:09:15.271932Z"
    }
   },
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# inicializar busca de hiperparametros\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Definindo as distribuições dos hiperparâmetros\n",
    "param_dist = {\n",
    "    'n_estimators': np.arange(100, 1000, 100),  # Lista de valores discretos\n",
    "    'max_depth': np.arange(5, 50, 5),  # Lista de valores discretos\n",
    "    'min_samples_split': np.arange(2, 20, 2),  # Lista de valores discretos\n",
    "    'min_samples_leaf': np.arange(1, 20, 2),  # Lista de valores discretos\n",
    "    'max_features': ['sqrt', 'log2', None],  # Lista de valores discretos\n",
    "}\n",
    "\n",
    "# Inicializar o RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Configurar o RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    scoring='r2',  # Métrica para avaliar as combinações\n",
    "    cv=5,  # Número de folds na validação cruzada\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Usar todos os processadores disponíveis\n",
    ")\n",
    "\n",
    "\n",
    "start = timer()\n",
    "# Adicionar tqdm para monitorar o progresso\n",
    "for i in tqdm(range(10), desc=\"RandomizedSearchCV progress\"):\n",
    "    random_search.n_iter = i + 1\n",
    "    random_search.fit(X_train, y_train)\n",
    "end = timer()\n",
    "\n",
    "joblib.dump(random_search, './output/random_search_model.pkl')\n",
    "\n",
    "# Melhor combinação de hiperparâmetros\n",
    "print(\"Melhores hiperparâmetros encontrados:\")\n",
    "print(random_search.best_params_)\n",
    "\n",
    "# Melhor modelo treinado\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# Avaliar o melhor modelo nos dados de teste\n",
    "y_pred = best_rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "residuals = y_test - y_pred\n",
    "_, p_value_het, _, _ = het_breuschpagan(residuals, X_test)\n",
    "_, p_value_lev = levene(residuals, y_test)\n",
    "_, p_value_shap = shapiro(residuals)\n",
    "\n",
    "# Salvar os resultados no DataFrame\n",
    "results_df.loc[len(results_df)] = ['Random Forest', end - start, r2, p_value_shap, p_value_lev, p_value_het]\n",
    "\n",
    "\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": 66,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 5 Crisp-DM: Avaliação dos resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Teste de Resíduos:\n",
    "    - Normalidade: Teste de Shapiro-Wilk\n",
    "    - Homocedasticidade: Teste de Levene\n",
    "    - R2 Score: Coeficiente de Determinação\n",
    "    - AIC: Critério de Informação de Akaike \n",
    "    - BIC: Critério de Informação Bayesiano\n",
    "    - F-Test: Teste de Significância do Modelo\n",
    "    - T-Test: Teste de Significância dos Coeficientes"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T19:11:18.693444Z",
     "start_time": "2024-05-28T19:11:18.688935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Salvar o DataFrame em um arquivo CSV na pasta output\n",
    "results_df.to_csv('./output/test_results.csv', index=False)"
   ],
   "execution_count": 67,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T19:11:21.016479Z",
     "start_time": "2024-05-28T19:11:18.694445Z"
    }
   },
   "source": [
    "# plotando residuos dos modelos\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "# Garantir que não há valores inf ou NaN\n",
    "X_test = np.nan_to_num(X_test, nan=np.nan, posinf=np.nan, neginf=np.nan)\n",
    "y_test = np.nan_to_num(y_test, nan=np.nan, posinf=np.nan, neginf=np.nan)\n",
    "\n",
    "\n",
    "for i, model in enumerate([tpot, lr, best_rf]):\n",
    "    residuals = y_test - model.predict(X_test)\n",
    "    sns.histplot(residuals, ax=axs[i], kde=True)\n",
    "    axs[i].set_title(f\"Resíduos do modelo {type(model).__name__}\")\n",
    "    axs[i].set_xlabel(\"Resíduos\")\n",
    "    axs[i].set_ylabel(\"Frequência\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('./output/residuos.png')\n",
    "plt.show()\n"
   ],
   "execution_count": 68,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T19:11:21.264288Z",
     "start_time": "2024-05-28T19:11:21.017486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# plotar tempo de execução por R2 Score dos modelos\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Extrair os valores de R2 Score e tempo de execução do DataFrame\n",
    "\n",
    "r2_scores = results_df['r2'] \n",
    "tempos = results_df['execution_time']\n",
    "modelos = results_df['model']\n",
    "\n",
    "\n",
    "# Plotar o gráfico de tempo de execução por R2 Score\n",
    "\n",
    "ax.scatter(tempos, r2_scores, s=100)\n",
    "ax.set_xlabel('Tempo de Execução (s)')\n",
    "ax.set_ylabel('R2 Score')\n",
    "ax.set_title('Tempo de Execução por R2 Score dos Modelos')\n",
    "ax.set_xticks(tempos)\n",
    "\n",
    "# adicionar o nome dos modelos\n",
    "for i, modelo in enumerate(modelos):\n",
    "    ax.annotate(modelo, (tempos[i], r2_scores[i]), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "plt.savefig('./output/tempo_r2.png')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ],
   "execution_count": 69,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T19:21:13.473409Z",
     "start_time": "2024-05-28T19:21:12.267310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "# variáveis importantes do modelo de árvore de decisão\n",
    "\n",
    "# Extrair as variáveis importantes do modelo de árvore de decisão\n",
    "importances = best_rf.feature_importances_  \n",
    "indices = np.argsort(importances)[::-1] \n",
    "\n",
    "# Plotar as variáveis importantes   \n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.title(\"Importância das Variáveis da Árvore de Decisão\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), X.columns[indices], rotation=90)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.savefig('./output/importancia_variaveis_rf_RandomSearch.png')\n",
    "plt.show()\n",
    "\n",
    "# variáveis importantes do modelo de linear regression\n",
    "\n",
    "# Extrair as variáveis importantes do modelo de linear regression\n",
    "importances = np.abs(lr.coef_)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Plotar as variáveis importantes\n",
    "plt.figure(figsize=(15, 10))    \n",
    "plt.title(\"Importância das Variáveis da Regressão Linear\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), X.columns[indices], rotation=90)    \n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.savefig('./output/importancia_variaveis_lr.png')    \n",
    "plt.show()\n"
   ],
   "execution_count": 76,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T19:21:16.163431Z",
     "start_time": "2024-05-28T19:21:15.499946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# variáveis importantes do modelo TPOT      \n",
    "\n",
    "# Obtenha o pipeline final ajustado pelo TPOT\n",
    "pipeline = tpot.fitted_pipeline_\n",
    "\n",
    "# Acessar o RandomForestRegressor\n",
    "random_forest = pipeline.named_steps['randomforestregressor']\n",
    "\n",
    "# Verifique se o modelo é um RandomForestRegressor\n",
    "if isinstance(random_forest, RandomForestRegressor):\n",
    "    # Extraia os nomes de todas as colunas usadas no modelo\n",
    "    all_feature_names = X.columns # Isso inclui todas as colunas, numéricas e dummies\n",
    "\n",
    "    # Extrair as importâncias das features do RandomForestRegressor\n",
    "    rf_importances = random_forest.feature_importances_\n",
    "\n",
    "    # Verificar a quantidade de features\n",
    "    if len(rf_importances) == len(all_feature_names):\n",
    "        rf_feature_names = all_feature_names\n",
    "    else:\n",
    "        print(f\"Tamanho das importâncias do RandomForest: {len(rf_importances)}\")\n",
    "        print(f\"Tamanho dos nomes de todas as features: {len(all_feature_names)}\")\n",
    "        rf_feature_names = all_feature_names[:len(rf_importances)]  # Ajustar o tamanho\n",
    "\n",
    "    rf_indices = np.argsort(rf_importances)[::-1]\n",
    "\n",
    "    # Plotar as importâncias das features do RandomForestRegressor\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.title(\"Importâncias das Features (RandomForestRegressor)\")\n",
    "    plt.bar(range(len(rf_importances)), rf_importances[rf_indices], align='center')\n",
    "    plt.xticks(range(len(rf_importances)), [rf_feature_names[i] for i in rf_indices], rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./output/importancia_variaveis_rf_tpot.png')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"O modelo dentro do pipeline não corresponde ao esperado.\")"
   ],
   "execution_count": 77,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T20:04:05.493835Z",
     "start_time": "2024-05-28T20:04:05.450915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# salvar o tpot\n",
    "# Extraia o pipeline treinado\n",
    "trained_pipeline = tpot.fitted_pipeline_\n",
    "\n",
    "# Salve o pipeline treinado\n",
    "joblib.dump(trained_pipeline, './output/trained_pipeline.pkl')"
   ],
   "execution_count": 83,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 6 Crisp-DM: Implantação\n",
    "Nessa etapa colocamos em uso o modelo desenvolvido, normalmente implementando o modelo desenvolvido em um motor que toma as decisões com algum nível de automação."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### no nosso caso os modelos e os plots foram salvos em arquivos, podemos usar o streamlit para mostrar os plots e o melhor modelo em outro arquivo python."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
